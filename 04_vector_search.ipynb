{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100aec12",
   "metadata": {},
   "source": [
    "# Introduction to Vector Search\n",
    "\n",
    "Vector Search might sound scary and complicated, but it's actually really easy! And then really hard and complicated!\n",
    "\n",
    "We computed *embeddings* of audio snippets. Now, given some example, we want to find similar audio snippets in our dataset.  To do this, we'll use vector search over the embeddings.\n",
    "\n",
    "We'll start by doing *brute force nearest-neighbor search*. This is conceptually very easy: Just compare the query embedding to all of the target embeddings, and return the closest one(s).\n",
    "\n",
    "We'll also find that we need to have some good data mangement along the way - it's not enough to get the best embedding, we also need to know what audio it is associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d08058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 0 ‚Äì Create a query.\n",
    "# ------------------------------------------------------------\n",
    "# This should mostly use code you've already written for\n",
    "# previous exercises.\n",
    "# 1) Create a variable for a file-path to some audio.\n",
    "# 2) Load the audio.\n",
    "# 3) Run the audio through an embedding model (Perch?) and get\n",
    "#    the audio embedding. This is your query embedding.\n",
    "# ------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5e39d",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 1 ‚Äì Create an embeddings dataset.\n",
    "# ------------------------------------------------------------\n",
    "# This also should rely heavily on code you've already \n",
    "# written for previous exercises... but will go a bit further.\n",
    "# 1) Get all the embeddings for your dataset (eg, your \n",
    "#    favorite anuraset site, or all of the anuraset data).\n",
    "# 2) Write the embeddings to disk, somehow. Check that you\n",
    "#    can reload the embeddings from disk, and that the \n",
    "#    reloaded embeddings match the originals.\n",
    "# 3) Given some choice of embedding from your dataset,\n",
    "#    write a function which gets the audio that the embedding\n",
    "#    came from.\n",
    "# ------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a41d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 2 ‚Äì Nearest-neighbor search.\n",
    "# ------------------------------------------------------------\n",
    "# Now we should have a *query embedding* and a numpy array \n",
    "# of *target embeddings.*\n",
    "# 1) Write a function which compares the query embedding to\n",
    "#    each of the target embeddings, and finds the one that is\n",
    "#    closest in Euclidean distance. Return the embedding and\n",
    "#    the associated audio.\n",
    "# 2) Update your function to take a `top_k` parameter. Then\n",
    "#    it should return a numpy array of embeddings (with shape\n",
    "#    [top_k, embedding_dim]) and an array of audio (with shape\n",
    "#    [top_k, 5*sample_rate]).\n",
    "# 3) Update your function to have some options for how to \n",
    "#    the nearest neighbor - try out cosine similarity and\n",
    "#    maximum inner product.\n",
    "# ------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e22b8",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 3 ‚Äì Displaying results.\n",
    "# ------------------------------------------------------------\n",
    "# Now that you have some top_k results, display them!\n",
    "# Draw a spectrogram and audio player for each result.\n",
    "# It's also helpful to write the filename and offset within\n",
    "# the file for each result, to make it possible to go\n",
    "# back and see the result in context.\n",
    "#\n",
    "# Extensions:\n",
    "# E1) Provide a button for 'relevant' / 'irrelevant'.\n",
    "# E2) Skip results which have already been marked.\n",
    "# ------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b24847",
   "metadata": {},
   "source": [
    "## Vector Databases in a Nutshell\n",
    "\n",
    "Brute force search is fantastic (and fast!) until you get to millions \n",
    "or billions of embeddings.\n",
    "\n",
    "(Micro-exercise: A 32-bit floating point number takes 4 bytes. \n",
    "How many embeddings can fit in RAM in the machine you're working on?\n",
    "How many hours of audio does that number of embeddings correspond to?\n",
    "How long would it take to run a brute-force search on that many embeddings?)\n",
    "\n",
    "When the number of embeddings becomes enormous, vector databases become\n",
    "sort of helpful!\n",
    "\n",
    "The idea of a vector database is to find *approximate* nearest neighbors\n",
    "quickly. This is done by *indexing* the data. There is an enormous literature\n",
    "on ways to do this well, but a good cartoon-version of what works well is \n",
    "*hierarchical k-means*. You cluster the data into k clusters, then cluster\n",
    "all the data assigned to each cluster centroid, and so on. Then to find \n",
    "nearest neighbors, you find the nearest top-centroid, then the nearest centroid\n",
    "at the second level, and so on.\n",
    "\n",
    "(More info than you need: this hierarchical k-means procedure has trouble when\n",
    "searching for something near the cluster boundary. Various tricks can be introduced\n",
    "to deal with this. There is also a family of *graph-based* indices, which\n",
    "are really cool mathematically and work pretty great, but deep in the weeds.)\n",
    "\n",
    "In my opinion, the best vector database in 2025 is called **usearch**. It's great because:\n",
    "\n",
    "* It is self-contained, with almost no dependencies: It has one job, and it does it well.\n",
    "* It can use an *on-disk* index! Most of the popular vector databases only work with embeddings in RAM, in order to give results as fast as possible. Using an on-disk index lets you scale to a much larger number of vectors for far less money.\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 427 ms, total: 2min 9s\n",
      "Wall time: 17.9 s\n",
      "100000\n",
      "\n",
      "time to run exact search: \n",
      "CPU times: user 18.1 ms, sys: 1 Œºs, total: 18.1 ms\n",
      "Wall time: 18 ms\n",
      "\n",
      "time to run approximate search: \n",
      "CPU times: user 1.02 ms, sys: 0 ns, total: 1.02 ms\n",
      "Wall time: 1.02 ms\n",
      "\n",
      "time to run approximate search from disk: \n",
      "CPU times: user 3.46 ms, sys: 3.99 ms, total: 7.44 ms\n",
      "Wall time: 7.44 ms\n"
     ]
    }
   ],
   "source": [
    "from usearch import index as uindex\n",
    "import numpy as np\n",
    "\n",
    "# For \"free\", here's an example of how to use usearch to index \n",
    "# and search some vectors.\n",
    "\n",
    "# Create the index, specifying the size of the vectors, \n",
    "# data type (dtype), and the metric to use.\n",
    "ui = uindex.Index(ndim=512, metric=\"L2sq\", dtype='f16')\n",
    "\n",
    "# Make some random data.\n",
    "n = 100_000\n",
    "keys = np.arange(n)\n",
    "vectors = np.random.rand(n, 512).astype(np.float32)\n",
    "print('\\ntime to create the index: ')\n",
    "%time ui.add(keys, vectors)\n",
    "\n",
    "print(len(ui.keys))\n",
    "\n",
    "# Make a random query.\n",
    "query = np.random.rand(512).astype(np.float32)\n",
    "\n",
    "print('\\ntime to run exact search: ')\n",
    "%time exact_top_k = ui.search(query, count=5, exact=True)\n",
    "\n",
    "print('\\ntime to run approximate search: ')\n",
    "%time approx_top_k = ui.search(query, count=5, exact=False)\n",
    "\n",
    "# TODO: Write some code measuring the proportion of exact_top_k\n",
    "# that are in approx_top_k. This is a *recall* metric.\n",
    "\n",
    "# Save the index to disk.\n",
    "ui.save(\"/tmp/index.bin\")\n",
    "\n",
    "# Use the on-disk index.\n",
    "ui2 = uindex.Index()\n",
    "ui2.view(\"/tmp/index.bin\")\n",
    "# Check that the loaded index is the same as the original.\n",
    "assert np.all(np.array(ui2.keys) == np.array(ui.keys))\n",
    "\n",
    "print('\\ntime to run approximate search from disk: ')\n",
    "%time approx_disk_top_k = ui2.search(query, count=5, exact=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c54aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 4 ‚Äì Embeddings usearch.\n",
    "# ------------------------------------------------------------\n",
    "# Do all the same stuff again, but this time with embeddings\n",
    "# from the Perch model.\n",
    "#\n",
    "# 1) Create a usearch index for the embeddings, and insert\n",
    "#    the embeddings into it.\n",
    "# 2) Save the index to disk, and load it again.\n",
    "# 3) Create a query embedding, and search the index for the\n",
    "#    nearest neighbors.\n",
    "# 4) Display the results, with a spectrogram of the query\n",
    "#    and the nearest neighbors.\n",
    "# 5) Measure the recall of the approximate search.\n",
    "# ------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21eab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227733"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ce597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
