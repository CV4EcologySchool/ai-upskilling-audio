{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adeaa261",
   "metadata": {},
   "source": [
    "# Fast Data Pipeline with Threading\n",
    "\n",
    "The GIL means that threads are not always helpful in Python, but there are two special cases where Python threading can be helpful:\n",
    "* I/O operations can occur without blocking the GIL, and\n",
    "* Calls to C++/Rust libraries (eg, many librosa operations) release the GIL while doing the heavy lifting.\n",
    "\n",
    "In both of these cases, we can improve execution speed by parallelizing effectively. \n",
    "\n",
    "This is particularly important for *data pipelines*. When training a model, we typically need to feed it subsets of our (gigantic, too big to fit in memory) dataset. Without threading, we need to load the next batch of data, wait for the model to evaluate and update, then load the next batch of data, and so on. This means that our fancy GPU is going to waste time while we load the data!\n",
    "\n",
    "Instead, we can load data *while* the model is running, and (hopefully) have the next batch of data ready and waiting. This greatly improves throughput. At the same time, we can make the data loader multi-threaded, to load data from more files in parallel (ie, faster).\n",
    "\n",
    "Let's start with a very simple example of how to use a `ThreadPoolExecutor`.\n",
    "\n",
    "To use the executor:\n",
    "1) Set it up, with some number of `max_workers`.\n",
    "2) Use `executor.submit(fn, arg1, arg2, ...)` to give the workers some work. The worker will run the submitted function, and evaluate it with the provided arguments - `fn(arg1, arg2, ...)`. This submit call returns a *future* object, which you should store for later to get the results.\n",
    "3) Get results from the future objects.\n",
    "\n",
    "Here's some example code to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256a8b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The function we want the workers to evaluate.\n",
    "fun = lambda a: a**2\n",
    "\n",
    "# Create an `executor` that we can pass work to.\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "  results = []\n",
    "  for i in range(10):\n",
    "    # Each result is a `future` object, which can tell us whether\n",
    "    # it is still running, and eventually provide a result.\n",
    "    results.append(executor.submit(fun, i))\n",
    "  results = [r.result() for r in results]\n",
    "  print(results)\n",
    "\n",
    "# We can also use a `map` approach more concisely.\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "  # map_results is a generator, yielding results as they are ready.\n",
    "  map_results = executor.map(fun, range(10))\n",
    "  print(list(map_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from typing import Generator\n",
    "from etils import epath\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tqdm\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AudioExample:\n",
    "  audio: np.ndarray\n",
    "  file_id: str\n",
    "  offset: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 0 ‚Äì Plain Old Data Loader\n",
    "# ------------------------------------------------------------\n",
    "# First, write a data loader which loads audio data from a\n",
    "# directory. Feel free to re-use your answer from Exercise 2\n",
    "# in the `03_anuraset_train` notebook.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def audio_chunk_dataloader(\n",
    "      file_glob, target_sample_rate, window_size_s, shuffle=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        file_glob: str, glob pattern for the audio files\n",
    "        target_sample_rate: int, sample rate to load the audio files\n",
    "        window_size_s: float, size of the audio chunks in seconds\n",
    "        shuffle: bool, whether to shuffle the order of the audio files in the glob; use a fixed seed for reproducibility\n",
    "    Yields:\n",
    "        audio_window: np.ndarray, audio chunk\n",
    "        file: str, path to the audio file\n",
    "        offset: float, start time of the audio chunk in seconds\n",
    "\n",
    "    Hint:\n",
    "    for file in glob:\n",
    "      for audio_window in file:\n",
    "        yield audio_window, file, offset\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "## Test:\n",
    "DATA_DIR   = Path('/mnt/class_data/anuraset')\n",
    "RAW_DIR    = DATA_DIR / 'raw_data'         # long recordings (.wav)\n",
    "\n",
    "file_glob = str(RAW_DIR / '**/*.wav')\n",
    "target_sample_rate = 16000\n",
    "window_size_s = 5.0\n",
    "dataloader = audio_chunk_dataloader(file_glob, target_sample_rate, window_size_s, shuffle=True)\n",
    "num_to_test = 15\n",
    "for i, (audio_chunk, file, offset) in tqdm(enumerate(dataloader)):\n",
    "    print(f\"Loaded {file} at {offset:.2f}s\")\n",
    "    display(Audio(audio_chunk, rate=target_sample_rate))\n",
    "    if i > num_to_test: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b047b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 1 ‚Äì Threaded Data Loader\n",
    "# ------------------------------------------------------------\n",
    "# Next, write a threaded version of the data loader.\n",
    "# Once you have an implementation that is working, play with\n",
    "# different values of `max_workers` to see how it affects\n",
    "# the speed of loading the data. What's optimal?\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def audio_chunk_dataloader_threaded(\n",
    "      file_glob, target_sample_rate, window_size_s, \n",
    "      shuffle=False, max_workers=2):\n",
    "  \"\"\"Threaded version of the audio chunk data loader.\"\"\"\n",
    "  raise NotImplementedError(\n",
    "      'Implement the threaded_data_loader function to load audio files from a directory.'\n",
    "  )\n",
    "\n",
    "file_glob = str(RAW_DIR / '**/*.wav')\n",
    "target_sample_rate = 16000\n",
    "window_size_s = 5.0\n",
    "dataloader = audio_chunk_dataloader(file_glob, target_sample_rate, window_size_s, shuffle=True)\n",
    "num_to_test = 15\n",
    "for i, (audio_chunk, file, offset) in tqdm(enumerate(dataloader)):\n",
    "    print(f\"Loaded {file} at {offset:.2f}s\")\n",
    "    display(Audio(audio_chunk, rate=target_sample_rate))\n",
    "    if i > num_to_test: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üìù Exercise 2 ‚Äì Fix a Bug!\n",
    "# ------------------------------------------------------------\n",
    "# Our current data iterator is pretty good, but has a subtle \n",
    "# failure mode: If we process the data slower than the \n",
    "# iterator loads the data, we can wind up with an ever-growing \n",
    "# backlog of loaded data, until we run out of memory. Refactor \n",
    "# the data loader so that it only preloads a fixed number of \n",
    "# examples at a time.\n",
    "# ------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
